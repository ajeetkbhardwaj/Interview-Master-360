{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"Interview Master 360  <p>A Comprehensive Guide to Mastering Technical Interviews</p>"},{"location":"datastructureAndalgorithm/Quest-1/","title":"Quest-1 :","text":"<ol> <li> <p>Explain how would you reverse an array in place. Inplace : without using extra space we modify the array to become reversed</p> </li> <li> <p>What is difference between array and linked list ?</p> </li> <li> <p>Key Difference : Data Organization, Memory management and Complexity Analysis</p> </li> <li> <p>Can you explain, when we should prefer to use array or linked lists ?</p> </li> <li>Arrays : Need for direct or random access like LookUp Table, When data will remain unchanged most of the time but requires most of time to access the elements.</li> <li>Linked Lists : Frequent insertions and deletions are expected, especially in the middle. The exact size of the list isn\u2019t known in advance, and you want the memory to be used flexibly. The primary operations are sequential, such as iteration from the beginning to the end.</li> </ol>"},{"location":"frameworks/Apache%20AirFlow/airflow/","title":"AirFlow","text":"<ol> <li>Apache Airflow with Astro : Automate and orchestrate your ML workflows using Airflow with Astronomer, ensuring your pipelines run seamlessly.</li> </ol>"},{"location":"frameworks/Apache%20Flink/flank/","title":"Apache Flank","text":""},{"location":"frameworks/Apache%20Kafka/kafka/","title":"Apache Kafka","text":""},{"location":"frameworks/Apache%20Wayang/wayang/","title":"wayang","text":""},{"location":"frameworks/Apache%20Wayang/wayang/#cross-platform-data-processing","title":"Cross-platform data processing","text":"<ul> <li>Introduction to Wayang: a platform for cross-framework data processing, allowing optimizations across Spark, Flink, and Relational Databases.</li> <li>Sessions about data systems research at IITD, guiding participants interested in pursuing higher studies, and research success stories.</li> <li>Lab: Hands-on exercises with Wayang.</li> </ul>"},{"location":"mlAlgorithms/intro/","title":"ML Algorithms","text":""},{"location":"mlFoundation/intro/","title":"ML Foundation","text":""},{"location":"mlPractice/intro/","title":"ML Practice","text":""},{"location":"mlSystems/Quest-10/","title":"Quest 10","text":"Model Deployment and Monitoring  <ol> <li>What is model deployment, and why is it challenging?</li> </ol> Answer  1. A process of packaging trained model and integrate it into the production system using REST API, where model can serve prediction on new unseen data to the user. Hence It bridges the gap between developement and serving to the end users(real world usecase).   2. Deployment into the production system become challenging due to the following     - Enviroment Mismatch from Developement to Deployment    - Model Serialization : Choosing the right format (e.g., Joblib, Pickle, ONNX, TorchScript) that is portable and secure.    - Infrastructure Readiness : We have to setup servers, containers or use cloud services to serve prediction at scale    - Latency and Throughput Issues :  Ensuring low prediction time, especially for real-time applications.    - Monitoriing and Observability : Detecting model or data drift or outage quickly    - Data and Model Version Control : Managing multiple version of model and dataset and track each version of model live.  <ol> <li>Can you describe how many different ways to deploy a machine learning model ?</li> </ol>  Answer   There are multiple ways to deploy a machine learning model, each suited to different use cases, latency requirements, infrastructure, and scalability needs. Thus, comprehensive list of main deployment strategies are as follows 1. Batch Inference : We perform predict on large batches of data at scheduled intervals (e.g., nightly reports or churn scoring).It only usefull when we don't need  real-time response. Tools : Apache Spark, Apache Airflow, Azure Data Factory etc. 2. Online(Real-time) Inference : Our model serve instant predictions through APIs for use cases needing low latency (e.g., recommendation systems, real-time fraud detection). It uses frameworks like Flask, FastAPI, TensorFlow Serving, TorchServe etc to build API. 3. Edge Deployment : We deploy our models to the edge devices like mobile, IoT, embedded systems etc for localized or offline inference. It uses frameworks like TensorFlow Lite, ONNX, Apple Core ML etc 4. Streaming Deployment : Continuously ingest and infer data streams in near real-time (e.g., sensor data, financial market feeds). Tools: Kafka + Faust, Spark Streaming, Apache Flink. 5. Containerized Deployment : Package models and dependencies into containers like Docker for environment consistency and portability. Orchestrate with Kubernetes, AWS ECS for scaling and management. 6. Model-as-a-Service (MaaS) : Use managed cloud platforms that provide hosting, scaling, and monitoring out of the box. Platforms: AWS SageMaker, Azure Machine Learning, Google Vertex AI, Databricks Model Serving.  <ol> <li>What is a REST API, and how do you use it to deploy models?</li> </ol>  Answer  <ol> <li>Can you explain CI/CD Pipeline into the MLOps ?</li> </ol>  Answer  <ol> <li>How do you monitor the performance of a deployed model?</li> </ol>  Answer  <ol> <li>What are some common tools for model monitoring and logging?</li> </ol>  Answer  <ol> <li>Describe a scenario where you had to roll back a deployed model.</li> </ol>  Answer  <ol> <li> <p>How do you handle model drift in production?</p> </li> <li> <p>What is canary deployment and why is it usefull ?</p> </li> <li> <p>Explain the concept of A/B testing in the context of model deployment.</p> </li> <li> <p>11. What are the key considerations for scaling a machine learning model?</p> </li> <li> <p>How do you ensure the security of your deployed models?</p> </li> </ol>"},{"location":"mlSystems/Quest-10/#template","title":"template :","text":"Answer"},{"location":"mlSystems/Quest-10/#references-and-reading-materials","title":"References and Reading Materials","text":"<p>[1]. https://skphd.medium.com/model-deployment-and-monitoring-interview-questions-and-answers-68cd7f48c29b \\ [2]. https://www.datacamp.com/blog/mlops-interview-questions \\ [3]. https://www.micro1.ai/interview-prep/mlops-engineer-interview-questions \\</p>"},{"location":"mlSystems/Quest-9/","title":"Quest 9","text":"<p>What is MLOps and how does it differ from DevOps?</p> <p>Describe the key stages of the MLOps lifecycle.</p> <p>What is model drift, and how would you monitor for it in production?  \u00a0 </p> <p>How would you implement a CI/CD pipeline for a machine learning model?  \u00a0 </p> <p>What is the purpose of a feature store in an ML system?  \u00a0 </p> <p>Explain the difference between Canary and Blue-Green deployment strategies for ML models.  \u00a0 </p> <p>How does data version control impact the machine learning lifecycle?  \u00a0 </p> <p>What are the challenges of maintaining consistent environments across the ML lifecycle, and how can containerization (e.g., Docker) address them?  \u00a0 </p> <p>Explain how you have used Docker containers or Kubernetes in deploying machine learning models.  \u00a0 </p> <p>What is the purpose of an orchestration tool like Airflow or Kubeflow in an ML pipeline?  \u00a0 </p>"}]}